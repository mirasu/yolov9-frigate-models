# Configuraci√≥n de YOLOv9 para Frigate

Has compilado con √©xito tres variantes del modelo **YOLOv9** a formato ONNX.

## Ubicaci√≥n de los archivos
- **YOLOv9-E (Extended/Power):** `/home/mirasu/yolov9-p.onnx` (265 MB) - *M√°xima precisi√≥n*
- **YOLOv9-S (Small):** `/home/mirasu/yolov9-s.onnx` (39 MB) - *Equilibrio*
- **YOLOv9-T (Tiny):** `/home/mirasu/yolov9-t.onnx` (9 MB) - *M√°xima velocidad*

## Integraci√≥n en Frigate (`config.yml`)

Elige el modelo seg√∫n tu hardware. El modelo **Tiny** es excelente para CPUs poco potentes, mientras que el **Extended (p)** es ideal si tienes un procesador moderno o iGPU.

### Ejemplo de configuraci√≥n
```yaml
detectors:
  ov:
    type: openvino
    device: AUTO

model:
  path: /config/model_cache/yolov9-s.onnx # Cambia a -p o -t seg√∫n prefieras
  input_tensor: nchw
  input_pixel_format: rgb
  width: 640
  height: 640
  labelmap_path: /config/model_cache/coco_labels.txt
```

### Diferencias de rendimiento
- **Tiny (t):** Muy bajo consumo de CPU, ideal para muchas c√°maras.
- **Small (s):** Buen punto medio para detecci√≥n de personas/objetos peque√±os.
- **Extended (p):** Pesado, pero con la mejor detecci√≥n disponible en YOLOv9.


### Notas Importantes
1. **Labels:** YOLOv9 usa las 80 clases de COCO. Si no tienes el archivo de etiquetas, puedes crearlo con la lista est√°ndar de COCO (person, bicycle, car, motorcyle, etc.).
2. **Dimensiones:** El modelo se export√≥ con una resoluci√≥n de **640x640**. Aseg√∫rate de que coincida en la configuraci√≥n.
3. **Rutas:** Recuerda mapear el volumen en Docker para que Frigate vea el archivo `.onnx` (ejemplo: `-v /home/mirasu/yolov9-p.onnx:/config/model_cache/yolov9-p.onnx:ro`).

### Conversi√≥n a TensorRT (.engine)
Si decides usar una GPU Nvidia, puedes convertir el ONNX a un engine optimizado usando el script proporcionado:
```bash
python3 /workspace/convert_onnx_to_trt.py --onnx /home/mirasu/yolov9-p.onnx --output /home/mirasu/yolov9-p.engine
```
Y luego cambia el detector en Frigate a `tensorrt`.

---

## üê≥ Uso con Docker

Si prefieres usar la imagen Docker para distribuir o servir los modelos, sigue estos pasos:

### 1. Construir la imagen
Desde la ra√≠z del repositorio:
```bash
docker build -t yolov9-models-frigate:latest .
```

### 2. Ejecutar y verificar
La imagen est√° basada en Alpine y simplemente contiene los archivos en `/models`.
```bash
docker run --rm yolov9-models-frigate:latest ls -lh /models
```

### 3. Extraer modelos desde Docker (opcional)
Si necesitas sacar un modelo espec√≠fico de la imagen construida:
```bash
docker run --rm -v $(pwd):/output yolov9-models-frigate:latest cp /models/yolov9-s-320.onnx /output/
```

---

## üöÄ Notas sobre el Hardware
- **CPU / OpenVINO:** Recomendado usar los modelos de **320px** para menor latencia.
- **GPU / TensorRT:** Los modelos de **640px** ofrecen la mejor precisi√≥n si tienes potencia suficiente.

---

## üõ†Ô∏è Herramienta de Conversi√≥n (YOLOv9 a ONNX)

Si necesitas exportar tus propios modelos o resoluciones personalizadas, ahora incluimos un entorno de exportaci√≥n completo en la carpeta `exporter/`.

### 1. Construir la imagen de conversi√≥n
```bash
cd exporter
docker build -t yolov9-exporter .
```

### 2. Exportar un modelo nuevo
Este comando descarga autom√°ticamente los pesos (.pt) de YOLOv9 y los convierte a ONNX:

```bash
# Ejemplo: Exportar YOLOv9-c con entrada de 416px
docker run --rm -v $(pwd):/app/export yolov9-exporter \
    --weights yolov9-c.pt \
    --include onnx \
    --imgsz 416 416
```

*El modelo resultante aparecer√° en tu carpeta local `exporter/`.*

### Caracter√≠sticas del Exportador:
- Basado en **Python 3.10** y **PyTorch (CPU)**.
- Incluye el parche necesario para cargar pesos en versiones modernas de PyTorch (`weights_only=False`).
- Repositorio oficial de **WongKinYiu/yolov9** pre-instalado.
